<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>XiaFan's Vision</title><link>https://blog.motofans.club</link><description>不过经验之谈</description><copyright>XiaFan's Vision</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://blog.motofans.club</link></image><lastBuildDate>Thu, 04 Jul 2024 15:58:54 +0000</lastBuildDate><managingEditor>XiaFan's Vision</managingEditor><ttl>60</ttl><webMaster>XiaFan's Vision</webMaster><item><title>安全的使用 Cert Manager</title><link>https://blog.motofans.club/post/24.html</link><description>## 前言&#13;
&#13;
在 Kubernetes 上使用 Cert Manager 的 ACME DNS Challenge 方式能够很轻松的为域名签发一张受信任的泛域名证书。</description><guid isPermaLink="true">https://blog.motofans.club/post/24.html</guid><pubDate>Thu, 04 Jul 2024 15:58:27 +0000</pubDate></item><item><title>Nginx-Ingress 一致性哈希</title><link>https://blog.motofans.club/post/23.html</link><description>有没有办法让同一个客户端的请求落在同一个 Pod 上面？&#13;
&#13;
在回答这个问题之前我们先来看看 Nginx-Ingress 是如何工作的。</description><guid isPermaLink="true">https://blog.motofans.club/post/23.html</guid><pubDate>Thu, 04 Jul 2024 15:57:13 +0000</pubDate></item><item><title>AKS 上面的坑</title><link>https://blog.motofans.club/post/22.html</link><description>我们有两套 AKS （Azure Kubernetes Service），一套用于测试环境，另一套则是投产使用。</description><guid isPermaLink="true">https://blog.motofans.club/post/22.html</guid><pubDate>Thu, 04 Jul 2024 15:56:40 +0000</pubDate></item><item><title>Garage: S3 兼容对象存储</title><link>https://blog.motofans.club/post/21.html</link><description>## 背景&#13;
&#13;
一直以来，要怎么能够让在 EPIC-KBS9 上部署的 Seafile 能够稳定高效的访问到 Riverbed CX570 的 ZFS 阵列都是让我觉得需要改进的地方。</description><guid isPermaLink="true">https://blog.motofans.club/post/21.html</guid><pubDate>Thu, 04 Jul 2024 15:55:49 +0000</pubDate></item><item><title>个人云存储方案设计</title><link>https://blog.motofans.club/post/20.html</link><description>*前排劝退，这不是一个免费的个人云存储方案，它的实现需要你投入一定的成本。</description><guid isPermaLink="true">https://blog.motofans.club/post/20.html</guid><pubDate>Thu, 04 Jul 2024 15:54:53 +0000</pubDate></item><item><title>Python 使用标准库获取网卡的 IP</title><link>https://blog.motofans.club/post/19.html</link><description>很多时候需要在 Python 获取指定网卡的 IP 地址。</description><guid isPermaLink="true">https://blog.motofans.club/post/19.html</guid><pubDate>Thu, 04 Jul 2024 15:54:05 +0000</pubDate></item><item><title>OpenWRT + 移远 EC20 接入 LTE</title><link>https://blog.motofans.club/post/18.html</link><description>## 前言&#13;
&#13;
在 [OpenWRT Stable Release 编译 ](https://blog.motofans.club/post/6.html) 这篇博文中我提到了我在使用 EC20 实现一个 CPE 设备。</description><guid isPermaLink="true">https://blog.motofans.club/post/18.html</guid><pubDate>Thu, 04 Jul 2024 15:49:44 +0000</pubDate></item><item><title>认识固态硬盘</title><link>https://blog.motofans.club/post/17.html</link><description>&lt;h2&gt;前言&lt;/h2&gt;&#13;
&lt;p&gt;「本文面向企业科普/市场提供」&lt;/p&gt;&#13;
&lt;h2&gt;闪存的定义&lt;/h2&gt;&#13;
&lt;p&gt;闪存是一种固态技术，使用闪存芯片写入和存储数据，它使用非易失性存储器，这意味着当电源关闭时数据不会丢失。</description><guid isPermaLink="true">https://blog.motofans.club/post/17.html</guid><pubDate>Thu, 04 Jul 2024 15:47:13 +0000</pubDate></item><item><title>更好的内网穿透: Boringproxy</title><link>https://blog.motofans.club/post/16.html</link><description>## 背景&#13;
&#13;
家里面没有固定的公网 IP 地址，路由器又不是最外面的一层，因此 DDNS 也没法搞。</description><guid isPermaLink="true">https://blog.motofans.club/post/16.html</guid><pubDate>Thu, 04 Jul 2024 15:46:28 +0000</pubDate></item><item><title>Charmed Kubernetes - 3: Upgrade Kubernetes Cluster</title><link>https://blog.motofans.club/post/15.html</link><description>## Infrastructure updates&#13;
&#13;
### Containerd&#13;
&#13;
```&#13;
juju upgrade-charm containerd --path=./containerd&#13;
&#13;
```&#13;
&#13;
### ETCD&#13;
&#13;
```&#13;
juju upgrade-charm etcd --path=./etcd&#13;
juju config etcd channel=3.4/stable&#13;
juju attach etcd etcd=./resources/etcd/etcd.snap&#13;
&#13;
```&#13;
&#13;
### EasyRSA&#13;
&#13;
```&#13;
juju upgrade-charm easyrsa --path=./easyrsa --resource esayrsa=./resources/easyrsa/easyrsa.tgz&#13;
&#13;
```&#13;
&#13;
### Calico CNI&#13;
&#13;
```&#13;
juju upgrade-charm calico --path=./calico \\&#13;
    --resource calico=./resources/calico/calico.gz \\&#13;
    --resource calico-node-image=./resources/calico/calico-node-image.gz \\&#13;
    --resource calico-upgrade=./resources/calico/calico-upgrade.gz&#13;
&#13;
```&#13;
&#13;
## Upgrading Kubernetes&#13;
&#13;
### KubeAPI Load Balancer&#13;
&#13;
```&#13;
juju upgrade-charm kubeapi-load-balancer --path=./kubeapi-load-balancer&#13;
juju upgrade-charm keepalived --path=./keepalived&#13;
&#13;
```&#13;
&#13;
### Kubernetes-Master Units&#13;
&#13;
```&#13;
juju upgrade-charm kubernetes-master --path=./kubernetes-master \\&#13;
    --resource cni-amd64=./resources/kubernetes-master/cni-amd64.tgz \\&#13;
    --resource cni-arm64=./resources/kubernetes-master/cni-arm64.tgz \\&#13;
    --resource cni-s390x=./resources/kubernetes-master/cni-s390x.tgz&#13;
juju attach kubernetes-master core=./resources/core/core.snap&#13;
juju attach kubernetes-master cdk-addons=./resources/kubernetes-master/cdk-addons.snap&#13;
juju attach kubernetes-master kube-apiserver=./resources/kubernetes-master/kube-apiserver.snap&#13;
juju attach kubernetes-master kube-controller-manager=./resources/kubernetes-master/kube-controller-manager.snap&#13;
juju attach kubernetes-master kube-scheduler=./resources/kubernetes-master/kube-scheduler.snap&#13;
juju attach kubernetes-master kube-proxy=./resources/kubernetes-master/kube-proxy.snap&#13;
juju attach kubernetes-master kubectl=./resources/kubernetes-master/kubectl.snap&#13;
&#13;
juju config kubernetes-master channel=1.22/stable&#13;
juju run-action kubernetes-master/0 upgrade&#13;
juju run-action kubernetes-master/1 upgrade&#13;
&#13;
```&#13;
&#13;
### Update Relation&#13;
&#13;
```&#13;
juju add-relation kubernetes-master:loadbalancer-external kubeapi-load-balancer:lb-consumers&#13;
juju add-relation kubernetes-master:loadbalancer-internal kubeapi-load-balancer:lb-consumers&#13;
&#13;
```&#13;
&#13;
### Kubernetes-Worker Units&#13;
&#13;
```&#13;
juju upgrade-charm kubernetes-worker --path=./kubernetes-worker \\&#13;
    --resource cni-amd64=./resources/kubernetes-worker/cni-amd64.tgz&#13;
juju attach kubernetes-worker kube-proxy=./resources/kubernetes-worker/kube-proxy.snap&#13;
juju attach kubernetes-worker kubectl=./resources/kubernetes-worker/kubectl.snap&#13;
juju attach kubernetes-worker kubelet=./resources/kubernetes-worker/kubelet.snap&#13;
&#13;
juju config kubernetes-worker channel=1.22/stable&#13;
juju run-action kubernetes-worker/0 upgrade&#13;
juju run-action kubernetes-worker/1 upgrade&#13;
&#13;
```。</description><guid isPermaLink="true">https://blog.motofans.club/post/15.html</guid><pubDate>Thu, 04 Jul 2024 15:45:26 +0000</pubDate></item><item><title>Charmed Kubernetes - 2: Deploy Kubernetes Cluster</title><link>https://blog.motofans.club/post/14.html</link><description>In this section, I will show how to deploy Kubernetes 1.21 with Calico CNI plugin.&#13;
&#13;
Please ensure that you have a sufficient number of nodes prepared and have already installed Ubuntu Server 20.04.&#13;
&#13;
The same deployment method is applicable at least until version 1.23 and has been verified to be upgradable to the current latest version 1.27 in subsequent articles.&#13;
&#13;
## Add a Model&#13;
&#13;
The model holds a specific deployment. It is a good idea to create a new one specifically for each deployment.&#13;
&#13;
```&#13;
juju add-model k8s-lab&#13;
&#13;
```&#13;
&#13;
Remember that you can have multiple models on each controller, so you can deploy multiple Kubernetes clusters, or other applications.&#13;
&#13;
## Machine Preparation&#13;
&#13;
### Add some machines&#13;
&#13;
For a Production-Ready Charmed Kubernetes, you should have at least three etcd nodes, two master nodes, and several worker nodes. All these nodes should have password-less login set up in advance.&#13;
&#13;
:::tip{title='Note'}&#13;
the master and etcd are not deployed on the same node. Although they can be deployed on the same node, I recommend deploying etcd separately.&#13;
:::&#13;
&#13;
```&#13;
juju switch k8s-lab&#13;
# ETCD&#13;
juju add-machine &lt;ssh:ares@100.64.1.121&gt;&#13;
juju add-machine &lt;ssh:ares@100.64.1.122&gt;&#13;
juju add-machine &lt;ssh:ares@100.64.1.123&gt;&#13;
# Master&#13;
juju add-machine &lt;ssh:ares@100.64.1.124&gt;&#13;
juju add-machine &lt;ssh:ares@100.64.1.125&gt;&#13;
# Worker&#13;
juju add-machine &lt;ssh:ares@100.64.1.126&gt;&#13;
juju add-machine &lt;ssh:ares@100.64.1.127&gt;&#13;
# kubeapi-load-balancer&#13;
# If you are using an external load balancer, these two machines are not necessary.&#13;
juju add-machine &lt;ssh:ares@100.64.1.128&gt;&#13;
juju add-machine &lt;ssh:ares@100.64.1.129&gt;&#13;
&#13;
```&#13;
&#13;
### View existing machines&#13;
&#13;
Run the following command to see if the machine has been set up. Also, make sure to remember the machine's ID because we'll need it for our deployment later on.&#13;
&#13;
```&#13;
juju status&#13;
Model    Controller  Cloud/Region            Version  SLA          Timestamp&#13;
k8s-lab  infra-demo  ares-homelab/default  2.9.25   unsupported  02:09:31Z&#13;
&#13;
Machine  State    DNS           Inst id              Series  AZ  Message&#13;
0        started  100.64.1.121  manual:100.64.1.121  focal       Manually provisioned machine&#13;
1        started  100.64.1.122  manual:100.64.1.122  focal       Manually provisioned machine&#13;
...&#13;
6        started  100.64.1.127  manual:100.64.1.127  focal       Manually provisioned machine&#13;
7        started  100.64.1.128  manual:100.64.1.128  focal       Manually provisioned machine&#13;
8        started  100.64.1.129  manual:100.64.1.129  focal       Manually provisioned machine&#13;
&#13;
```&#13;
&#13;
## Deploy Kubernetes&#13;
&#13;
Now, we begin deploying Kubernetes according to the roles assigned to the machine in the Machine Preparation step.&#13;
&#13;
Download https://git.motofans.club/Motofans/charmed-kubernetes/archive/Bugfix-Release_657.zip and unzip it.&#13;
&#13;
Please proceed with the following deployment command：&#13;
&#13;
:::warning{title='Note'}&#13;
At the beginning, we will not deploy it in a high-availability state. We will temporarily deploy only a single replica for each component.&#13;
&#13;
Please make sure to replace the 'service-cidr' and 'calico-cidr' with the appropriate values.&#13;
&#13;
We use Calico CNI and enable IgnoreLooseRPF, You need to install ethtool on the machine in advance.&#13;
:::&#13;
&#13;
```&#13;
# Core&#13;
for i in {0..7}; do&#13;
  juju scp resources/core/core.* $i:&#13;
  juju run --machine $i 'sudo snap ack /home/ubuntu/core.assert'&#13;
  juju run --machine $i 'sudo snap install --dangerous /home/ubuntu/core.snap'&#13;
done&#13;
&#13;
# EasyRSA&#13;
juju deploy --to 0 ./easyrsa&#13;
juju attach easyrsa easyrsa=./resources/easyrsa/easyrsa.tgz&#13;
&#13;
# ETCD&#13;
juju deploy --to 0 ./etcd \\&#13;
    --config bind_to_all_interfaces=false \\&#13;
    --config channel=3.4/stable&#13;
juju attach etcd snapshot=./resources/etcd/snapshot.gz&#13;
juju attach etcd etcd=./resources/etcd/etcd.snap&#13;
&#13;
# Containerd&#13;
juju deploy ./containerd&#13;
&#13;
# Kubernetes-master&#13;
# Disable the built-in dashboard&#13;
# Use the IPVS mode&#13;
juju deploy --to 3 ./kubernetes-master \\&#13;
    --config channel=1.21/stable \\&#13;
    --config service-cidr=172.31.192.0/21 \\&#13;
    --config enable-dashboard-addons=false \\&#13;
    --config image-registry=jcr.motofans.club/mirror/rocks.canonical.com/cdk \\&#13;
    --config proxy-extra-args='bind-address=0.0.0.0 proxy-mode=ipvs'&#13;
juju attach kubernetes-master core=./resources/core/core.snap&#13;
juju attach kubernetes-master cdk-addons=./resources/kubernetes-master/cdk-addons.snap&#13;
juju attach kubernetes-master kube-apiserver=./resources/kubernetes-master/kube-apiserver.snap&#13;
juju attach kubernetes-master kube-controller-manager=./resources/kubernetes-master/kube-controller-manager.snap&#13;
juju attach kubernetes-master kube-scheduler=./resources/kubernetes-master/kube-scheduler.snap&#13;
juju attach kubernetes-master kube-proxy=./resources/kubernetes-master/kube-proxy.snap&#13;
juju attach kubernetes-master kubectl=./resources/kubernetes-master/kubectl.snap&#13;
&#13;
# Kubernetes-worker&#13;
# Use the IPVS mode&#13;
juju deploy --to 5 ./kubernetes-worker \\&#13;
    --config channel=1.21/stable \\&#13;
    --config ingress=false \\&#13;
    --config proxy-extra-args='bind-address=0.0.0.0 proxy-mode=ipvs'&#13;
juju attach kubernetes-worker cni-amd64=./resources/kubernetes-worker/cni-amd64.tgz&#13;
juju attach kubernetes-worker kube-proxy=./resources/kubernetes-worker/kube-proxy.snap&#13;
juju attach kubernetes-worker kubectl=./resources/kubernetes-worker/kubectl.snap&#13;
juju attach kubernetes-worker kubelet=./resources/kubernetes-worker/kubelet.snap&#13;
&#13;
# Calico&#13;
juju deploy ./calico \\&#13;
    --config cidr=172.31.128.0/18 \\&#13;
    --config vxlan=Always \\&#13;
    --config ignore-loose-rpf=true&#13;
juju attach calico calico=./resources/calico/calico.gz&#13;
juju attach calico calico-node-image=./resources/calico/calico-node-image.gz&#13;
juju attach calico calico-upgrade=./resources/calico/calico-upgrade.gz&#13;
&#13;
# Add relate&#13;
juju relate etcd:certificates easyrsa:client&#13;
juju relate kubernetes-master:kube-control kubernetes-worker:kube-control&#13;
juju relate kubernetes-master:certificates easyrsa:client&#13;
juju relate kubernetes-worker:certificates easyrsa:client&#13;
juju relate kubernetes-master:etcd etcd:db&#13;
juju relate containerd:containerd kubernetes-worker:container-runtime&#13;
juju relate containerd:containerd kubernetes-master:container-runtime&#13;
juju relate kubernetes-master:kube-api-endpoint kubernetes-worker:kube-api-endpoint&#13;
juju relate calico:etcd etcd:db&#13;
juju relate calico:cni kubernetes-master:cni&#13;
juju relate calico:cni kubernetes-worker:cni&#13;
&#13;
```&#13;
&#13;
Juju is now busy creating instances, installing software and connecting the different parts of the cluster together, which can take several minutes. You can monitor what’s going on by running:&#13;
&#13;
```&#13;
watch -c juju status --color&#13;
&#13;
```&#13;
&#13;
Once all the workloads are displayed as active, we can start increasing the number of replicas for the components by running:&#13;
&#13;
```&#13;
juju add-unit etcd --to 1&#13;
juju add-unit etcd --to 2&#13;
juju add-unit kubernetes-master --to 4&#13;
juju add-unit kubernetes-worker --to 6&#13;
&#13;
```&#13;
&#13;
## KubeAPI Load Balancer&#13;
&#13;
Once the scaling is complete, We've got two Master nodes, and to spread the load across both, we need to bring in a load balancer (LB). This LB can be set up using a controller internally, or externally using F5 or other load balancing devices.&#13;
&#13;
### Software LB&#13;
&#13;
*If you are using an external load balancer, you can skip this part.*&#13;
&#13;
Here's how to set up the software LB using a controller.&#13;
&#13;
```&#13;
export VIP=100.64.1.128&#13;
export VIP_HOSTNAME=kube-api.motofans.club&#13;
juju deploy --to 7 ./kubeapi-load-balancer&#13;
&#13;
juju config kubernetes-master extra_sans='$VIP $VIP_HOSTNAME'&#13;
juju config kubeapi-load-balancer extra_sans='$VIP $VIP_HOSTNAME'&#13;
&#13;
juju remove-relation kubernetes-master:kube-api-endpoint kubernetes-worker:kube-api-endpoint&#13;
&#13;
juju relate kubernetes-master:kube-api-endpoint kubeapi-load-balancer:apiserver&#13;
juju relate kubernetes-worker:kube-api-endpoint kubeapi-load-balancer:website&#13;
juju relate kubeapi-load-balancer:certificates easyrsa:client&#13;
juju relate kubernetes-master:loadbalancer kubeapi-load-balancer:loadbalancer&#13;
&#13;
```&#13;
&#13;
Now, we have a load balancer distributing requests across two master nodes.&#13;
&#13;
You may have noticed that the load balancer itself isn't highly available as it's deployed on a specific node. If this node experiences issues, worker nodes will be unable to access the master nodes. We can solve this issue by deploying Keepalived:&#13;
&#13;
```&#13;
export VIP=100.64.1.110&#13;
export VIP_HOSTNAME=kube-api.motofans.club&#13;
juju deploy ./keepalived&#13;
&#13;
juju config keepalived virtual_ip=$VIP&#13;
juju config keepalived vip_hostname=$VIP_HOSTNAME&#13;
juju config kubeapi-load-balancer extra_sans='$VIP $VIP_HOSTNAME'&#13;
juju config kubernetes-master extra_sans='$VIP $VIP_HOSTNAME'&#13;
&#13;
juju add-relation keepalived:juju-info kubeapi-load-balancer:juju-info&#13;
juju add-relation keepalived:lb-sink kubeapi-load-balancer:website&#13;
juju add-relation keepalived:loadbalancer kubernetes-master:loadbalancer&#13;
juju add-relation keepalived:website kubernetes-worker:kube-api-endpoint&#13;
&#13;
juju remove-relation kubernetes-worker:kube-api-endpoint kubeapi-load-balancer:website&#13;
juju remove-relation kubernetes-master:loadbalancer kubeapi-load-balancer:loadbalancer&#13;
&#13;
juju add-unit kubeapi-load-balancer --to 8&#13;
&#13;
juju config kubernetes-master proxy-extra-args='bind-address=0.0.0.0 proxy-mode=ipvs master=https://kube-api.motofans.club:443'&#13;
juju config kubernetes-worker proxy-extra-args='bind-address=0.0.0.0 proxy-mode=ipvs master=https://kube-api.motofans.club:443'&#13;
&#13;
```&#13;
&#13;
### External Load Balancer&#13;
&#13;
**Recommendation**&#13;
&#13;
*If you are not using an external load balancer, you can skip this part.*&#13;
&#13;
When using an external load balancer, you need to distribute the traffic to two Master nodes, and it is recommended to ensure high availability of the external load balancer in a production environment.&#13;
&#13;
```&#13;
juju config kubernetes-master extra_sans='$VIP $VIP_HOSTNAME'&#13;
juju config kubernetes-master loadbalancer-ips='$VIP $VIP_HOSTNAME'&#13;
&#13;
```&#13;
&#13;
## Retrieve Config File&#13;
&#13;
Finally, You can use the following command to retrieve the cluster config file:&#13;
&#13;
```&#13;
mkdir -p .kube&#13;
juju scp kubernetes-master/0:config ~/.kube/config&#13;
&#13;
```&#13;
&#13;
## Use CoreDNS charm&#13;
&#13;
CoreDNS has been the default DNS provider for Charmed Kubernetes clusters since 1.14. It will be installed and configured as part of the install process of Charmed Kubernetes.&#13;
&#13;
For additional control over CoreDNS, you can also deploy it into the cluster using the [[CoreDNS Kubernetes operator charm](https://charmhub.io/coredns)](https://charmhub.io/coredns).&#13;
&#13;
```&#13;
juju config -m k8s-lab kubernetes-master dns-provider=none&#13;
juju add-k8s k8s-cloud --controller infra-demo&#13;
juju add-model k8s-model k8s-cloud&#13;
cat ./resources/coredns-image.tgz&#13;
juju deploy ./coredns --resource coredns-image=./resources/coredns-image.tgz&#13;
juju offer coredns:dns-provider&#13;
juju consume -m k8s-lab k8s-model.coredns&#13;
juju relate -m k8s-lab coredns kubernetes-master&#13;
&#13;
```&#13;
&#13;
Once everything settles out, new or restarted pods will use the CoreDNS charm as their DNS provider. The CoreDNS charm config allows you to change the cluster domain, the IP address or config file to forward unhandled queries to, add additional DNS servers, or even override the Corefile entirely.。</description><guid isPermaLink="true">https://blog.motofans.club/post/14.html</guid><pubDate>Thu, 04 Jul 2024 15:44:28 +0000</pubDate></item><item><title>Charmed Kubernetes - 1: Bootstrap a Controller</title><link>https://blog.motofans.club/post/13.html</link><description>This section will cover how to deploy a Controller in a bare-metal environment.&#13;
&#13;
For The official documentation is already well-prepared for public cloud environments. If you are not deploying in a bare-metal environment, Please refer to https://ubuntu.com/kubernetes/docs for more information.&#13;
&#13;
## Install Juju&#13;
&#13;
Juju is a tool that helps automate the deployment, configuration, and management of applications in cloud environments. It makes it easier to manage multiple applications and their interactions within the cloud.&#13;
&#13;
```bash&#13;
sudo snap install juju --channel=2.9 --classic&#13;
```&#13;
&#13;
## Setting up password-less login&#13;
&#13;
Generate SSH keys:&#13;
&#13;
```&#13;
ssh-keygen&#13;
```&#13;
&#13;
Copy the generated SSH keys to the specified address&#13;
&#13;
&gt; Replace 'ares@100.64.1.81' with the actual username and IP address. The following steps will continue in the same manner. There will be no further prompts.&#13;
&#13;
```&#13;
ssh-copy-id ares@100.64.1.81&#13;
```&#13;
&#13;
## Create a Cloud&#13;
&#13;
Since we are not generating the nodes to be deployed via a cloud environment or infrastructure API, please enter 'manual' here.&#13;
&#13;
&gt; You can give a name to your private cloud. I'll use 'ares-homelab' here.&#13;
&#13;
```&#13;
juju add-cloud&#13;
&#13;
This operation can be applied to both a copy on this client and to the one on a controller.&#13;
No current controller was detected and there are no registered controllers on this client: either bootstrap one or register one.&#13;
Cloud Types&#13;
  lxd&#13;
  maas&#13;
  manual&#13;
  openstack&#13;
  vsphere&#13;
&#13;
Select cloud type: manual&#13;
&#13;
Enter a name for your manual cloud: ares-homelab&#13;
&#13;
Enter the ssh connection string for controller, username@&lt;hostname or IP&gt; or &lt;hostname or IP&gt;: ares@100.64.1.81&#13;
&#13;
Cloud 'ares-homelab' successfully added to your local client.&#13;
&#13;
```&#13;
&#13;
## Bootstrap a Controller&#13;
&#13;
The Juju controller is used to manage the software deployed through Juju, from deployment to upgrades to day-two operations. One Juju controller can manage multiple projects or workspaces, which in Juju are known as ‘models’.&#13;
&#13;
&gt; You can give a name to your Controller. I'll use 'infra-demo' here.&#13;
&#13;
```Bash&#13;
juju bootstrap ares-homelab infra-demo --no-gui&#13;
```&#13;
&#13;
## Enable Controller HA&#13;
&#13;
In a production environment, it is recommended to deploy the Controller in high-availability (HA) mode, with a suggested number of 3 or 5 nodes. If you are only testing, this step can be skipped.&#13;
&#13;
&gt; Enabling HA requires a minimum of three nodes&#13;
&#13;
```Bash&#13;
ssh-copy-id ares@100.64.1.82&#13;
ssh-copy-id ares@100.64.1.83&#13;
juju add-machine -m controller &lt;ssh:ares@100.64.1.82&gt;&#13;
juju add-machine -m controller &lt;ssh:ares@100.64.1.83&gt;&#13;
juju machines -m controller&#13;
juju enable-ha --to=1,2&#13;
juju controllers --refresh&#13;
```。</description><guid isPermaLink="true">https://blog.motofans.club/post/13.html</guid><pubDate>Thu, 04 Jul 2024 15:43:11 +0000</pubDate></item><item><title>Jenkins 使用 Inbound Agent</title><link>https://blog.motofans.club/post/12.html</link><description>在 Jenkins 使用 distributed builds 时，可能会遇到一些特定的网络环境使得 Jenkins Master 无法通过 SSH Agent 一类的方式实现主动的与 Jenkins Node 建立链接。</description><guid isPermaLink="true">https://blog.motofans.club/post/12.html</guid><pubDate>Thu, 04 Jul 2024 15:31:17 +0000</pubDate></item><item><title>从网络位置安装 MS Office</title><link>https://blog.motofans.club/post/11.html</link><description>可不可以在局域网内使用 Samba (共享文件夹) 来安装 Office 2016/2019 呢？&#13;
&#13;
当然是可以的。</description><guid isPermaLink="true">https://blog.motofans.club/post/11.html</guid><pubDate>Thu, 04 Jul 2024 15:30:18 +0000</pubDate></item><item><title>使用 GCS 的 Maven 中央仓库</title><link>https://blog.motofans.club/post/10.html</link><description>本文最后修订时间为 2022 年 07 月 25 日，以下描述基于本文最后修订时间可能会有调整。</description><guid isPermaLink="true">https://blog.motofans.club/post/10.html</guid><pubDate>Thu, 04 Jul 2024 15:29:33 +0000</pubDate></item><item><title>客制化 Redhat/CentOS 8</title><link>https://blog.motofans.club/post/8.html</link><description>## 背景&#13;
&#13;
Redhat/CentOS 在 release 8 后，没有再提供 minimal 镜像。</description><guid isPermaLink="true">https://blog.motofans.club/post/8.html</guid><pubDate>Thu, 04 Jul 2024 15:19:58 +0000</pubDate></item><item><title>Jumpserver 切换 SQLiite 到 MYSQL</title><link>https://blog.motofans.club/post/7.html</link><description>## 背景&#13;
&#13;
因为升级和分布式部署，现在需要将 jumpserver 的数据库从 SQLite 切换为 MySQL/Mariadb&#13;
&#13;
网上搜了一圈，没见到有人写这个，可能没有倒霉蛋需要填这个坑吧。</description><guid isPermaLink="true">https://blog.motofans.club/post/7.html</guid><pubDate>Thu, 04 Jul 2024 15:15:40 +0000</pubDate></item><item><title>OpenWRT Stable Release 编译</title><link>https://blog.motofans.club/post/6.html</link><description>## 前言&#13;
&#13;
我是不太喜欢 OpenWRT 的，相比来说 RouterOS 是我更中意的。</description><guid isPermaLink="true">https://blog.motofans.club/post/6.html</guid><pubDate>Thu, 04 Jul 2024 15:14:15 +0000</pubDate></item><item><title>Linux 的路由表</title><link>https://blog.motofans.club/post/5.html</link><description>## 基础&#13;
&#13;
在一个在未经过修改的系统上，内建了以下几张路由表&#13;
&#13;
- **local**: 本地表，处理服务器内部的流量，并包括以太网适配器和广播流量，在大部分情况下不应该修改或是删除这张表。</description><guid isPermaLink="true">https://blog.motofans.club/post/5.html</guid><pubDate>Thu, 04 Jul 2024 15:13:29 +0000</pubDate></item><item><title>使用 ULogd 收集 Iptables 的日志</title><link>https://blog.motofans.club/post/4.html</link><description>## 背景&#13;
&#13;
在充当 NAT 网关的两个 CentOS 7 服务器上，因为审计需求，需要打开 Iptables 的 Log。</description><guid isPermaLink="true">https://blog.motofans.club/post/4.html</guid><pubDate>Thu, 04 Jul 2024 15:12:36 +0000</pubDate></item><item><title>OSPF + tun2socks 实现全局代理</title><link>https://blog.motofans.club/post/3.html</link><description>*本文的方案是为标准代理服务器 HTTP(S) 与 Socks 而设计的。</description><guid isPermaLink="true">https://blog.motofans.club/post/3.html</guid><pubDate>Thu, 04 Jul 2024 15:10:24 +0000</pubDate></item><item><title>Azure Blob 兼容 S3-API</title><link>https://blog.motofans.club/post/2.html</link><description>尽管 S3 似乎已经成为云存储的事实标准，不过 Azure Blob 并不支持。</description><guid isPermaLink="true">https://blog.motofans.club/post/2.html</guid><pubDate>Thu, 04 Jul 2024 11:23:46 +0000</pubDate></item><item><title>高性能 DNS 服务器: SmartDNS</title><link>https://blog.motofans.club/post/1.html</link><description>在广域网上提供的公共 DNS 实际上是有 QOS 限制的，并且由于中国大陆特殊的网络情况，经常容易获得被污染的 DNS 解析。</description><guid isPermaLink="true">https://blog.motofans.club/post/1.html</guid><pubDate>Thu, 04 Jul 2024 10:37:49 +0000</pubDate></item></channel></rss>